---
title: "Stability selection pour la prédiction de la résistance d'une souche bactérienne à un antibiotique"
subtitle: "M1 parcours SSD -- UE Apprentissage Statistique I"

date: "29/04/2022"

author:
  \begin{tabular}{ccc}
  Vadim \textsc{Bertrand} & Lola \textsc{Cottin} & Marie \textsc{Gaffet}
  \end{tabular}

output:
  pdf_document:
    number_sections: true
    citation_package: biblatex

bibliography: stabsel.bib

urlcolor: blue

header-includes:
   - \usepackage{caption}
   - \usepackage{longtable}
   - \usepackage{booktabs}
   - \usepackage{subcaption}
   - \usepackage{float}
   - \usepackage[backend=biber,style=numeric,sorting=none]{biblatex}
   - \makeatletter\renewcommand*{\fps@figure}{H}\makeatother
---

```{r setup, include = F}
knitr::opts_chunk$set(echo = F, message = F, warning = F, results = F)
knitr::opts_chunk$set(fig.width = 6, fig.height = 3, fig.align = "center")
```

```{r, lib}
library(ggpubr)
```

# Introduction

Certaines souches bactériennes présentent une résistance particulière aux antibiotiques développés pour lutter contre elles. \
Cette résistance peut être modélisée par une régression logistique ayant pour variables explicatives l'activation ou non des gènes du génome des souches.
Seulement, le grand nombre de gènes (plusieurs dizaines de milliers) impose de sélectionner les gènes explicatifs avant d'entrainer le modèle de régression logistique.
Pour cela des méthodes de régression pénalisant le nombre de variables sélectionnées existent.
Lasso notamment peut être utilisé, mais quand les variables mises en jeu sont corrélées il présente l'inconvénient d'être instable et de sélectionner plus de variables que nécessaire. \
Pour palier ce problème, la technique de stability selection \cite{stabsel} peut être intéressante.
Il s'agit de répéter plusieurs fois l'ajustement d'une régression logistique Lasso basée sur un sous-échantillonnage du jeu de données et d'en déduire la fréquence de sélection des variables par l'ensemble des régressions.
Les variables dont la fréquence de sélection dépasse un seuil donné sont enfin utilisées pour l'ajustement d'une régression logistique non pénalisée. \
Nous verrons ici comment implémenter la procédure de stability selection sur R, puis nous commenterons les résultats obtenus selon le seuil de sélection en les comparant à ceux d'une régression logistique Lasso "classique".

# Implémentation de la stability selection

```{r, source}
source("stabsel_func.R")
source("stabsel_data.R")
source("stabsel_fig.R")
```

L'ensemble du code mise en oeuvre pour l'implémentation et l'application de la stability selection est organisé en quatre fichiers :

  * ***stabsel_func.R*** contient les fonctions relatives à la stability selection (ajustement et évaluation) ;
  * ***stabsel_data.R*** pour importer le jeu de données utilisé ;
  * ***stabsel_run.R*** entraîne et évalue l'ensemble des modèles, puis sauvegarde un résumé des résultats ;
  * ***stabsel_fig.R*** définie les fonctions utiles pour l'affichage des résultats.

Le code étant présent et commenté en annexes, nous ne reviendrons donc que brièvement sur les éléments clés :

  * nous nous sommes appuyé sur la librairie [glmnet](https://cran.r-project.org/web/packages/glmnet/index.html) pour ajuster les régressions logistiques Lasso ;
  * par défaut, les sous-échantillons sélectionnés aléatoirement sont de taille $N/2$ avec $N$ la taille de l'échantillon ;
  * les modèles Lasso et sous-échantillons utilisés pour construire le chemin de stabilité sont au nombre de 100 ;
  * le maximum des fréquences, ou probabilités, de sélection selon les valeurs de lambda du chemin de stabilité est utilisé pour sélectionner les variables stables selon le seuil de stabilité souhaité ;
  * les seuils de stabilité considérés sont : ${0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1}$ ;
  * nous avons également implémenté la procédure de cross-validation pour ajuster l'hyper-paramètre du seuil de stabilité :
    * la procédure utilise 10 folds par défaut ;
    * deux seuils de stabilité optimaux sont retournés : l'un minimisant l'erreur, l'autre minimisant le nombre de variables tel que l'erreur se situe à un écart type du minimum ;
    * l'erreur utilisée est $100 - t_{agrément}$ avec $t_{agrément}$ le taux d'agrément, ou taux de bonne classification global.

# Application à la prédiction de la résistance d'une souche bactérienne à un antibiotique

```{r, load}
load("data/summaries.Rdata")
load("data/paths.Rdata")
mods_summary <- rbind(lasso_summary, stab_sel_summary)
mods_summary$nzero <- as.integer(mods_summary$nzero)
```

```{r, fig_chemins, fig.cap = "Chemins de stabilité (à gauche) et de régularisation (à droite)"}
fig_stab <- get_fig_stab(stab_path)
fig_reg <- get_fig_reg(reg_path)
ggarrange(fig_stab, fig_reg, ncol = 2)
```

```{r, fig_roc_auc, fig.height = 6, fig.cap = "Courbes ROC (en haut) et diagramme à bâtons représentant les AUC (en bas) des différents modèles"}
mods_roc <- get_rocs(X.train, y.train, X.test, y.test, mods_summary)
fig_roc <- get_fig_roc(mods_roc)
fig_auc <- get_fig_auc(mods_roc)
ggarrange(fig_roc, fig_auc, nrow = 2, common.legend = TRUE, legend = "right")
```

```{r, fig_score, fig.height = 6, fig.cap = "Taux d'agrément en fonction de la taille du support (en haut) et diagramme en bâtons des coefficients pour les différents taux d'agrément (en bas) des différents modèles"}
fig_nz_sco <- get_fig_nz_score(mods_summary)
fig_amp_sco <- get_fig_amp_score(mods_summary)
ggarrange(fig_nz_sco, fig_amp_sco, nrow = 2, common.legend = TRUE, legend = "right")
```

# Conclusion

Blabla

# Annexes

***stabsel_func.R***

```{r, code_func, code = readLines("stabsel_func.R", encoding = "UTF-8"), echo = T, eval = F}
```

***stabsel_data.R***

```{r, code_data, code = readLines("stabsel_data.R", encoding = "UTF-8"), echo = T, eval = F}
```

***stabsel_run.R***

```{r, code_run, code = readLines("stabsel_run.R", encoding = "UTF-8"), echo = T, eval = F}
```

***stabsel_fig.R***

```{r, code_run, code = readLines("stabsel_fig.R", encoding = "UTF-8"), echo = T, eval = F}
```

# Références
